{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2ECV8xtwXIyBeq61YUWJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniChinwendu/COMPUTATIONAL-CHEMISTRY-CHEMINFORMATICS/blob/main/PUBMED_AGENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "kaFnToAgiPjQ",
        "outputId": "1df25eda-6253-4a4e-9314-c8af83c54b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-00111a35-e634-4ba1-b38b-4dfd57870b74\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-00111a35-e634-4ba1-b38b-4dfd57870b74\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ALL DATA.csv to ALL DATA.csv\n",
            "User uploaded file \"ALL DATA.csv\" with length 308990 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install (alternative with pinned versions)\n",
        "# ============================================================================\n",
        "import subprocess\n",
        "subprocess.check_call(['pip', 'install', '-q',\n",
        "    'langchain>=0.3.0',\n",
        "    'langchain-core>=0.3.0',\n",
        "    'langchain-google-genai>=2.0.0',\n",
        "    'langgraph>=0.2.0',\n",
        "    'pydantic>=2.0',\n",
        "    'pandas',\n",
        "    'google-generativeai',\n",
        "    'requests'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLww2QXZh2XA",
        "outputId": "db961fe7-1483-4324-f281-0086c9b68491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cell 2: Setup - CHANGE YOUR EMAIL HERE!!!\n",
        "# ============================================================================\n",
        "import os, json, re, time, requests, pandas as pd\n",
        "from typing import TypedDict, Annotated, Sequence, List, Dict, Any\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"NCBI_EMAIL\"] = \"Ukaegbudaniel33@gmail.com\"  # â† CHANGE THIS!\n",
        "\n",
        "print(f\"âœ… Email: {os.getenv('NCBI_EMAIL')}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BaC1l_5fklDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cell 3: State\n",
        "# ============================================================================\n",
        "class CompoundState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    compound_name: str\n",
        "    search_query: str\n",
        "    pmids: List[str]\n",
        "    articles: List[Dict[str, Any]]\n",
        "    interactions: List[Dict[str, Any]]\n"
      ],
      "metadata": {
        "id": "k9zQvjOCkfFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cell 4: Tools\n",
        "# ============================================================================\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "@tool\n",
        "def search_pubmed(compound: str, max_results: int = 30) -> str:\n",
        "    \"\"\"Search PubMed for articles on a chemical compound with toxicology focus.\n",
        "\n",
        "    Args:\n",
        "        compound: The search query for PubMed (can include boolean operators)\n",
        "        max_results: Maximum number of results to return (default: 30)\n",
        "\n",
        "    Returns:\n",
        "        JSON string with list of PubMed IDs (pmids)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        email = os.getenv(\"NCBI_EMAIL\")\n",
        "        if not email or \"example\" in email:\n",
        "            raise ValueError(\"âŒ REPLACE YOUR EMAIL IN THE CODE!\")\n",
        "        url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\"db\": \"pubmed\", \"term\": compound, \"retmax\": min(max_results, 100),\n",
        "                  \"rettype\": \"xml\", \"tool\": \"agent\", \"email\": email}\n",
        "        response = requests.get(url, params=params, timeout=20)\n",
        "\n",
        "        root = ET.fromstring(response.text)\n",
        "        pmids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
        "\n",
        "        print(f\"  âœ“ Found {len(pmids)} articles\")\n",
        "        return json.dumps({\"pmids\": pmids})\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ {e}\")\n",
        "        return json.dumps({\"pmids\": []})\n",
        "\n",
        "@tool\n",
        "def fetch_pubmed_articles(pmids_list: str) -> str:\n",
        "    \"\"\"Fetch full article metadata from PubMed using PMIDs.\n",
        "\n",
        "    Args:\n",
        "        pmids_list: JSON string containing list of PubMed IDs\n",
        "\n",
        "    Returns:\n",
        "        JSON string with article titles and abstracts\n",
        "    \"\"\"\n",
        "    try:\n",
        "        pmids = json.loads(pmids_list)\n",
        "        if not pmids:\n",
        "            return json.dumps({\"articles\": []})\n",
        "        email = os.getenv(\"NCBI_EMAIL\")\n",
        "        articles = []\n",
        "        for i in range(0, len(pmids), 50):\n",
        "            batch = pmids[i:i+50]\n",
        "            url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "            params = {\"db\": \"pubmed\", \"id\": \",\".join(batch), \"rettype\": \"xml\", \"email\": email}\n",
        "            response = requests.get(url, params=params, timeout=20)\n",
        "\n",
        "            root = ET.fromstring(response.text)\n",
        "            for article in root.findall(\".//PubmedArticle\"):\n",
        "                pmid_elem = article.find(\".//PMID\")\n",
        "                title_elem = article.find(\".//ArticleTitle\")\n",
        "                abstract_elem = article.find(\".//AbstractText\")\n",
        "\n",
        "                pmid = pmid_elem.text if pmid_elem is not None else \"\"\n",
        "                title = title_elem.text if title_elem is not None else \"\"\n",
        "                abstract = abstract_elem.text if abstract_elem is not None else \"\"\n",
        "\n",
        "                if pmid and abstract:\n",
        "                    articles.append({\"pmid\": pmid, \"title\": title, \"abstract\": abstract})\n",
        "\n",
        "            time.sleep(0.5)\n",
        "        print(f\"  âœ“ Fetched {len(articles)} articles\")\n",
        "        return json.dumps({\"articles\": articles})\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ {e}\")\n",
        "        return json.dumps({\"articles\": []})\n",
        "\n",
        "@tool\n",
        "def extract_with_llm(article_data: str) -> str:\n",
        "    \"\"\"Extract molecular interactions and toxicological mechanisms from an article abstract using LLM.\n",
        "\n",
        "    Args:\n",
        "        article_data: JSON string with compound, abstract, and pmid fields\n",
        "\n",
        "    Returns:\n",
        "        JSON string with extracted interactions and confidence scores\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(article_data)\n",
        "        compound = data.get(\"compound\", \"\")\n",
        "        abstract = data.get(\"abstract\", \"\")\n",
        "        pmid = data.get(\"pmid\", \"\")\n",
        "\n",
        "        if not abstract or len(abstract) < 50:\n",
        "            return json.dumps({\"pmid\": pmid, \"interactions\": []})\n",
        "\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.1)\n",
        "        prompt = f\"\"\"You are a toxicology and molecular biology expert. Extract biological and toxicological information about {compound} from the following abstract.\n",
        "\n",
        "ABSTRACT:\n",
        "{abstract}\n",
        "\n",
        "Extract the following information if present:\n",
        "1. Proteins/enzymes that interact with {compound}\n",
        "2. Genes that are affected or regulated\n",
        "3. Cellular pathways impacted\n",
        "4. Organs or systems affected\n",
        "5. Toxicological mechanisms or effects\n",
        "6. Molecular targets\n",
        "7. the oragnism or specie\n",
        "\n",
        "CRITICAL: You MUST respond with ONLY valid JSON. No explanations, no markdown, just raw JSON.\n",
        "\n",
        "If you find relevant information, use this format:\n",
        "{{\"interactions\": [{{\"type\": \"protein/gene/pathway/mechanism/organ\", \"name\": \"specific_name\", \"interaction\": \"how_it_interacts_or_is_affected\",\"Organism or specie\":\"was_it human_zebrahfish_rats_or_mice\", \"confidence\": 0.9}}, ...]}}\n",
        "\n",
        "If NO relevant information found:\n",
        "{{\"interactions\": []}}\n",
        "\n",
        "Remember: Only respond with JSON, nothing else.\"\"\"\n",
        "\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "        # Clean up response - remove markdown code blocks if present\n",
        "        response_text = response.content.strip()\n",
        "        if response_text.startswith(\"```\"):\n",
        "            response_text = response_text.split(\"```\")[1]\n",
        "            if response_text.startswith(\"json\"):\n",
        "                response_text = response_text[4:]\n",
        "            response_text = response_text.strip()\n",
        "\n",
        "        try:\n",
        "            result = json.loads(response_text)\n",
        "        except:\n",
        "            result = {\"interactions\": []}\n",
        "\n",
        "        result[\"pmid\"] = pmid\n",
        "        return json.dumps(result)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"pmid\": pmid, \"interactions\": []})\n"
      ],
      "metadata": {
        "id": "HsFRo6Lgkw04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cell 5: Nodes\n",
        "# ============================================================================\n",
        "def search_node(state):\n",
        "    compound = state.get(\"compound_name\", \"\")\n",
        "\n",
        "    # Build a more targeted search query\n",
        "    # Prioritizes toxicology, molecular interaction, and mechanism studies\n",
        "    search_query = f'\"{compound}\" AND (toxicity OR toxicology OR \"molecular target\" OR protein OR gene OR pathway OR pharmacology OR mechanism OR hepatotoxicity OR nephrotoxicity OR neurotoxicity OR genotoxicity OR \"drug metabolism\" OR metabolism OR binding OR inhibitor OR receptor)'\n",
        "\n",
        "    print(f\"\\nðŸ” {compound}\")\n",
        "    print(f\"   Query: {search_query[:80]}...\")\n",
        "    result = json.loads(search_pubmed.invoke({\"compound\": search_query, \"max_results\": 50}))\n",
        "    return {**state, \"pmids\": result.get(\"pmids\", []), \"search_query\": search_query}\n",
        "\n",
        "def fetch_node(state):\n",
        "    pmids = state.get(\"pmids\", [])\n",
        "    if not pmids:\n",
        "        print(\"\\nðŸ“¥ No PMIDs to fetch\")\n",
        "        return state\n",
        "    print(f\"\\nðŸ“¥ Fetching...\")\n",
        "    result = json.loads(fetch_pubmed_articles.invoke(json.dumps(pmids)))\n",
        "    return {**state, \"articles\": result.get(\"articles\", [])}\n",
        "\n",
        "def extract_node(state):\n",
        "    articles, compound = state.get(\"articles\", []), state.get(\"compound_name\", \"\")\n",
        "    if not articles:\n",
        "        print(\"\\nðŸ§  No articles to extract\")\n",
        "        return state\n",
        "    print(f\"\\nðŸ§  Extracting interactions...\")\n",
        "    all_interactions = []\n",
        "\n",
        "    # Process all articles (or limit to 25 for speed)\n",
        "    max_articles = min(len(articles), 30)\n",
        "    for i, article in enumerate(articles[:max_articles]):\n",
        "        if not article.get(\"abstract\"):\n",
        "            continue\n",
        "        print(f\"  [{i+1}/{max_articles}]...\", end=\" \", flush=True)\n",
        "        result = json.loads(extract_with_llm.invoke(json.dumps({\n",
        "            \"compound\": compound,\n",
        "            \"abstract\": article[\"abstract\"],\n",
        "            \"pmid\": article[\"pmid\"]\n",
        "        })))\n",
        "        interactions = result.get(\"interactions\", [])\n",
        "        if interactions:\n",
        "            print(f\"âœ“ ({len(interactions)} found)\")\n",
        "            for inter in interactions:\n",
        "                all_interactions.append({\"pmid\": article[\"pmid\"], \"title\": article.get(\"title\", \"\"), **inter})\n",
        "        else:\n",
        "            print(\"âœ—\")\n",
        "        time.sleep(0.5)  # Reduced from 1s\n",
        "\n",
        "    return {**state, \"interactions\": all_interactions}\n"
      ],
      "metadata": {
        "id": "OX_mpTCvoYXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cell 6: Create Agent\n",
        "# ============================================================================\n",
        "def create_agent():\n",
        "    graph = StateGraph(CompoundState)\n",
        "    graph.add_node(\"search\", search_node)\n",
        "    graph.add_node(\"fetch\", fetch_node)\n",
        "    graph.add_node(\"extract\", extract_node)\n",
        "    graph.add_edge(START, \"search\")\n",
        "    graph.add_edge(\"search\", \"fetch\")\n",
        "    graph.add_edge(\"fetch\", \"extract\")\n",
        "    graph.add_edge(\"extract\", END)\n",
        "    return graph.compile()\n",
        "\n",
        "agent = create_agent()\n",
        "print(\"âœ… Agent ready!\\n\")\n"
      ],
      "metadata": {
        "id": "eNcxKWWeoNwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# Cell 7: Search function\n",
        "# ============================================================================\n",
        "def search_compound(compound_name: str):\n",
        "    print(f\"\\n{'='*70}\\n  ANALYZING: {compound_name}\\n{'='*70}\")\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=f\"Analyze {compound_name}\")],\n",
        "        \"compound_name\": compound_name,\n",
        "        \"search_query\": \"\",\n",
        "        \"pmids\": [],\n",
        "        \"articles\": [],\n",
        "        \"interactions\": []\n",
        "    }\n",
        "    result = agent.invoke(initial_state)\n",
        "    interactions = result.get(\"interactions\", [])\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  RESULTS: {len(interactions)} interactions extracted\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    if interactions:\n",
        "        df = pd.DataFrame(interactions)\n",
        "        # Display relevant columns\n",
        "        display_cols = [col for col in [\"compound_name\", \"pmid\", \"title\", \"name\", \"type\", \"interaction\", \"confidence\"] if col in df.columns]\n",
        "        print(df[display_cols].head(25).to_string(index=False))\n",
        "        print(f\"\\nâœ… Saved to {compound_name.lower().replace(' ', '_')}_interactions.csv\")\n",
        "        df.to_csv(f\"{compound_name.lower().replace(' ', '_')}_interactions.csv\", index=False)\n",
        "        return df\n",
        "    else:\n",
        "        print(\"âš ï¸ No interactions found. Try adjusting the compound name or search terms.\")\n",
        "    return pd.DataFrame()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c930d323-a5d4-443a-bd7d-f7a7bd17525b",
        "id": "dbyOpNr-fw0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Agent ready!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_search_compounds(csv_file_path: str, compound_column: str = \"compound\",\n",
        "                          output_file: str = \"all_interactions.csv\",\n",
        "                          start_index: int = 0,\n",
        "                          limit: int = None):\n",
        "    \"\"\"Process multiple compounds from CSV and save all interactions to one file.\"\"\"\n",
        "\n",
        "    # Load CSV with different encodings\n",
        "    print(f\"\\nðŸ“‚ Loading: {csv_file_path}\")\n",
        "\n",
        "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'utf-16']\n",
        "    df_input = None\n",
        "\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            df_input = pd.read_csv(csv_file_path, encoding=encoding)\n",
        "            print(f\"âœ“ Loaded {len(df_input)} rows (encoding: {encoding})\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    if df_input is None:\n",
        "        print(\"âŒ Could not read CSV file with any encoding!\")\n",
        "        return None\n",
        "\n",
        "    # Check column exists\n",
        "    if compound_column not in df_input.columns:\n",
        "        print(f\"âŒ Column '{compound_column}' not found!\")\n",
        "        print(f\"Available: {list(df_input.columns)}\")\n",
        "        return None\n",
        "\n",
        "    # Get unique compounds\n",
        "    compounds = df_input[compound_column].dropna().unique().tolist()\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  BATCH PROCESSING: {len(compounds)} unique compounds\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Apply limits\n",
        "    if limit:\n",
        "        compounds = compounds[start_index:start_index + limit]\n",
        "    else:\n",
        "        compounds = compounds[start_index:]\n",
        "\n",
        "    all_interactions = []\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    # Process each compound\n",
        "    for idx, compound in enumerate(compounds, start=start_index+1):\n",
        "        try:\n",
        "            print(f\"[{idx}/{len(compounds) + start_index}] {compound}...\", end=\" \", flush=True)\n",
        "\n",
        "            initial_state = {\n",
        "                \"messages\": [HumanMessage(content=f\"Analyze {compound}\")],\n",
        "                \"compound_name\": str(compound),\n",
        "                \"search_query\": \"\",\n",
        "                \"pmids\": [],\n",
        "                \"articles\": [],\n",
        "                \"interactions\": []\n",
        "            }\n",
        "            result = agent.invoke(initial_state)\n",
        "            interactions = result.get(\"interactions\", [])\n",
        "\n",
        "            if interactions:\n",
        "                print(f\"âœ“ ({len(interactions)})\")\n",
        "                all_interactions.extend(interactions)\n",
        "                successful += 1\n",
        "            else:\n",
        "                print(\"âœ—\")\n",
        "                failed += 1\n",
        "\n",
        "            # Checkpoint every 10\n",
        "            if idx % 10 == 0:\n",
        "                df_temp = pd.DataFrame(all_interactions)\n",
        "                df_temp.to_csv(output_file, index=False)\n",
        "                print(f\"   ðŸ’¾ Saved {len(all_interactions)} interactions\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ {str(e)[:40]}\")\n",
        "            failed += 1\n",
        "\n",
        "    # Final save\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  COMPLETE: {successful} success, {failed} failed\")\n",
        "    print(f\"  Total: {len(all_interactions)} interactions\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    if all_interactions:\n",
        "        df_results = pd.DataFrame(all_interactions)\n",
        "        df_results.to_csv(output_file, index=False)\n",
        "        print(f\"âœ… Saved to: {output_file}\\n\")\n",
        "        return df_results\n",
        "\n",
        "    return pd.DataFrame()"
      ],
      "metadata": {
        "id": "lEADnozIVSDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with just FIRST 50 compounds (quick test)\n",
        "results_df = batch_search_compounds(\n",
        "    csv_file_path=\"/content/ALL DATA.csv\",\n",
        "    compound_column=\"compound_name\",\n",
        "    output_file=\"all_interactions_sample.csv\",\n",
        "    limit=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMbapXdZS6sk",
        "outputId": "ac3eed7b-73ea-46a1-af3f-bba002a764f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“‚ Loading: /content/ALL DATA.csv\n",
            "âœ“ Loaded 1959 rows (encoding: latin-1)\n",
            "\n",
            "======================================================================\n",
            "  BATCH PROCESSING: 1836 unique compounds\n",
            "======================================================================\n",
            "\n",
            "[1/2] Acifluorfen... \n",
            "ðŸ” Acifluorfen\n",
            "   Query: \"Acifluorfen\" AND (toxicity OR toxicology OR \"molecular target\" OR protein OR ge...\n",
            "  âœ“ Found 50 articles\n",
            "\n",
            "ðŸ“¥ Fetching...\n",
            "  âœ“ Fetched 50 articles\n",
            "\n",
            "ðŸ§  Extracting interactions...\n",
            "  [1/30]... âœ—\n",
            "  [2/30]... âœ“ (4 found)\n",
            "  [3/30]... âœ“ (2 found)\n",
            "  [4/30]... âœ—\n",
            "  [5/30]... âœ“ (3 found)\n",
            "  [6/30]... âœ“ (2 found)\n",
            "  [7/30]... âœ“ (1 found)\n",
            "  [8/30]... âœ“ (5 found)\n",
            "  [9/30]... âœ“ (4 found)\n",
            "  [10/30]... âœ“ (4 found)\n",
            "  [11/30]... âœ“ (4 found)\n",
            "  [12/30]... âœ“ (11 found)\n",
            "  [13/30]... âœ—\n",
            "  [14/30]... âœ“ (2 found)\n",
            "  [15/30]... âœ“ (2 found)\n",
            "  [16/30]... âœ“ (18 found)\n",
            "  [17/30]... âœ“ (5 found)\n",
            "  [18/30]... âœ“ (12 found)\n",
            "  [19/30]... âœ—\n",
            "  [20/30]... âœ—\n",
            "  [21/30]... âœ“ (2 found)\n",
            "  [22/30]... âœ—\n",
            "  [23/30]... âœ—\n",
            "  [24/30]... âœ“ (5 found)\n",
            "  [25/30]... âœ“ (12 found)\n",
            "  [26/30]... âœ—\n",
            "  [27/30]... âœ“ (2 found)\n",
            "  [28/30]... âœ—\n",
            "  [29/30]... âœ“ (7 found)\n",
            "  [30/30]... âœ“ (3 found)\n",
            "âœ“ (110)\n",
            "[2/2] Sodium L-ascorbate... \n",
            "ðŸ” Sodium L-ascorbate\n",
            "   Query: \"Sodium L-ascorbate\" AND (toxicity OR toxicology OR \"molecular target\" OR protei...\n",
            "  âœ“ Found 50 articles\n",
            "\n",
            "ðŸ“¥ Fetching...\n",
            "  âœ“ Fetched 50 articles\n",
            "\n",
            "ðŸ§  Extracting interactions...\n",
            "  [1/30]... âœ“ (1 found)\n",
            "  [2/30]... âœ—\n",
            "  [3/30]... âœ—\n",
            "  [4/30]... âœ—\n",
            "  [5/30]... âœ—\n",
            "  [6/30]... âœ—\n",
            "  [7/30]... âœ—\n",
            "  [8/30]... âœ—\n",
            "  [9/30]... âœ—\n",
            "  [10/30]... âœ—\n",
            "  [11/30]... âœ“ (8 found)\n",
            "  [12/30]... âœ“ (3 found)\n",
            "  [13/30]... âœ“ (3 found)\n",
            "  [14/30]... âœ—\n",
            "  [15/30]... âœ—\n",
            "  [16/30]... âœ“ (2 found)\n",
            "  [17/30]... âœ“ (4 found)\n",
            "  [18/30]... âœ—\n",
            "  [19/30]... âœ—\n",
            "  [20/30]... âœ“ (1 found)\n",
            "  [21/30]... âœ—\n",
            "  [22/30]... âœ—\n",
            "  [23/30]... âœ“ (5 found)\n",
            "  [24/30]... âœ“ (1 found)\n",
            "  [25/30]... âœ“ (3 found)\n",
            "  [26/30]... âœ“ (2 found)\n",
            "  [27/30]... âœ“ (10 found)\n",
            "  [28/30]... âœ“ (5 found)\n",
            "  [29/30]... âœ“ (2 found)\n",
            "  [30/30]... âœ“ (3 found)\n",
            "âœ“ (53)\n",
            "\n",
            "======================================================================\n",
            "  COMPLETE: 2 success, 0 failed\n",
            "  Total: 163 interactions\n",
            "======================================================================\n",
            "\n",
            "âœ… Saved to: all_interactions_sample.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cell 8: RUN THIS IN NEW CELL:\n",
        "# ============================================================================\n",
        "results = search_compound(\"acetaminophen\")\n",
        "results = search_compound(\"caffeine\")\n",
        "results = search_compound(\"nicotine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1V9zWhRQwrs",
        "outputId": "878d8f97-3997-431c-99e5-92b0be25abc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  ANALYZING: acetaminophen\n",
            "======================================================================\n",
            "\n",
            "ðŸ” acetaminophen\n",
            "   Query: \"acetaminophen\" AND (toxicity OR toxicology OR \"molecular target\" OR protein OR ...\n",
            "  âœ“ Found 30 articles\n",
            "\n",
            "ðŸ“¥ Fetching...\n",
            "  âœ“ Fetched 27 articles\n",
            "\n",
            "ðŸ§  Extracting interactions...\n",
            "  [1/25]... âœ“ (7 found)\n",
            "  [2/25]... âœ—\n",
            "  [3/25]... âœ—\n",
            "  [4/25]... âœ“ (3 found)\n",
            "  [5/25]... âœ—\n",
            "  [6/25]... âœ—\n",
            "  [7/25]... âœ“ (13 found)\n",
            "  [8/25]... âœ“ (17 found)\n",
            "  [9/25]... âœ—\n",
            "  [10/25]... âœ—\n",
            "  [11/25]... âœ—\n",
            "  [12/25]... âœ“ (3 found)\n",
            "  [13/25]... âœ“ (2 found)\n",
            "  [14/25]... âœ—\n",
            "  [15/25]... âœ—\n",
            "  [16/25]... âœ“ (2 found)\n",
            "  [17/25]... âœ—\n",
            "  [18/25]... âœ—\n",
            "  [19/25]... âœ—\n",
            "  [20/25]... âœ“ (13 found)\n",
            "  [21/25]... âœ—\n",
            "  [22/25]... âœ—\n",
            "  [23/25]... âœ“ (8 found)\n",
            "  [24/25]... âœ—\n",
            "  [25/25]... âœ“ (10 found)\n",
            "\n",
            "======================================================================\n",
            "  RESULTS: 78 interactions extracted\n",
            "======================================================================\n",
            "\n",
            "    pmid                                                                                                                                        title                                                                  name                    type                                                                           interaction  confidence\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                                         acetaminophen                    drug                           enhanced absorption and plasma levels with ST36 acupuncture         0.9\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                                         acetaminophen                    drug                                          increased AUC and Cmax with ST36 acupuncture         0.9\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                                         acetaminophen                    drug                                                  shortened Tmax with ST36 acupuncture         0.9\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                                                 lungs                   organ                           elevated acetaminophen concentrations with ST36 acupuncture         0.7\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                                     delayed clearance toxicological mechanism                 acetaminophen clearance delayed at higher doses with ST36 stimulation         0.8\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                           prolonged systemic exposure    toxicological effect       acetaminophen systemic exposure prolonged at higher doses with ST36 stimulation         0.8\n",
            "41261684                Mechanism, research progress and warning of the effects of acupuncture at Zusanli point (ST36) on pharmacokinetics: A review.                                                                 liver                   organ changes in biomarkers associated with liver function under elevated compound exposure         0.6\n",
            "41254937                                         Sesamin alleviates drug-induced hepatotoxicity via autophagy enhancement and ferroptosis inhibition.                                                                 liver                   organ                                                                                injury         0.9\n",
            "41254937                                         Sesamin alleviates drug-induced hepatotoxicity via autophagy enhancement and ferroptosis inhibition.                                                        hepatic system                  system                                                                   acute liver failure         0.9\n",
            "41254937                                         Sesamin alleviates drug-induced hepatotoxicity via autophagy enhancement and ferroptosis inhibition.                                                          drug-induced toxicological mechanism                                                                   acute liver failure         0.8\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                                 liver                   organ                                       acetaminophen induces acute liver failure (ALF)         0.9\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                                 brain                   organ                            acetaminophen induces blood-brain barrier (BBB) impairment         0.9\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                             acute liver failure (ALF) toxicological mechanism                                                              induced by acetaminophen         0.9\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                  blood-brain barrier (BBB) impairment toxicological mechanism                                                  induced by acetaminophen-induced ALF         0.9\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                              arginase                 protein                              acetaminophen-induced ALF leads to arginase accumulation         0.8\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                        arginine (Arg)              amino acid                                    arginase accumulation leads to arginine deficiency         0.8\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                        mTORC1 pathway        cellular pathway        inhibited in BBB cells due to arginine deficiency in acetaminophen-induced ALF         0.8\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                              p70 ribosomal protein S6 kinase 1 (S6K1)                 protein       downstream protein of mTORC1, silencing shows similar effects as Arg deficiency         0.7\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy. eukaryotic translation initiation factor 4E binding protein 1 (4EBP1)                 protein       downstream protein of mTORC1, silencing shows similar effects as Arg deficiency         0.7\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                             autophagy        cellular pathway        activated in BBB cells due to arginine deficiency in acetaminophen-induced ALF         0.8\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                              Beclin-1                 protein                                 silencing partially reverses arginase-induced effects         0.7\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                            cell cycle        cellular process                               BBB cells arrest in G1 phase due to arginine deficiency         0.8\n",
            "41249150 Acute liver failure-induced arginine deficiency impairs blood-brain barrier via inhibiting mTORC1-S6K1/4EBP1 pathway and inducing autophagy.                                                    cell proliferation        cellular process                              suppressed in BBB cells due to acetaminophen-induced ALF         0.8\n",
            "41249093                                               A multi-omics landscape of programmed cell death in acetaminophen-induced acute kidney injury.                                                                kidney                   organ                                               affected by APAP-induced nephrotoxicity         0.9\n",
            "41249093                                               A multi-omics landscape of programmed cell death in acetaminophen-induced acute kidney injury. 884 genes related to 13 distinct forms of programmed cell death (PCD)                    gene                                            expression altered in APAP-injured kidneys         0.8\n",
            "\n",
            "âœ… Saved to acetaminophen_interactions.csv\n",
            "\n",
            "======================================================================\n",
            "  ANALYZING: caffeine\n",
            "======================================================================\n",
            "\n",
            "ðŸ” caffeine\n",
            "   Query: \"caffeine\" AND (toxicity OR toxicology OR \"molecular target\" OR protein OR gene ...\n",
            "  âœ“ Found 30 articles\n",
            "\n",
            "ðŸ“¥ Fetching...\n",
            "  âœ“ Fetched 26 articles\n",
            "\n",
            "ðŸ§  Extracting interactions...\n",
            "  [1/25]... âœ“ (7 found)\n",
            "  [2/25]... âœ—\n",
            "  [3/25]... âœ—\n",
            "  [4/25]... âœ“ (8 found)\n",
            "  [5/25]... âœ“ (5 found)\n",
            "  [6/25]... âœ“ (2 found)\n",
            "  [7/25]... âœ—\n",
            "  [8/25]... âœ“ (4 found)\n",
            "  [9/25]... âœ“ (2 found)\n",
            "  [10/25]... âœ“ (2 found)\n",
            "  [11/25]... âœ“ (9 found)\n",
            "  [12/25]... âœ“ (4 found)\n",
            "  [13/25]... âœ—\n",
            "  [14/25]... âœ—\n",
            "  [15/25]... âœ—\n",
            "  [16/25]... âœ“ (1 found)\n",
            "  [17/25]... âœ—\n",
            "  [18/25]... âœ“ (1 found)\n",
            "  [19/25]... âœ—\n",
            "  [20/25]... âœ“ (13 found)\n",
            "  [21/25]... âœ—\n",
            "  [22/25]... âœ“ (1 found)\n",
            "  [23/25]... âœ“ (1 found)\n",
            "  [24/25]... âœ—\n",
            "  [25/25]... âœ“ (1 found)\n",
            "\n",
            "======================================================================\n",
            "  RESULTS: 61 interactions extracted\n",
            "======================================================================\n",
            "\n",
            "    pmid                                                                                                                                     title                              name                    type                                                                                 interaction  confidence\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study.                           ADORA2A                 protein                    genotype influences the effect of caffeine on post-exercise iFABP levels         0.9\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study.                           ADORA2A                    gene      rs5751876 polymorphism influences the effect of caffeine on post-exercise iFABP levels         0.9\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study.                            CYP1A2                    gene rs762551 polymorphism may influence the effect of caffeine (but not observed in this study)         0.5\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study.                             iFABP                 protein                                  increased in plasma post-exercise, exacerbated by caffeine         0.9\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study.                         intestine                   organ                  acute damage to intestinal epithelial cells may be exacerbated by caffeine         0.8\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study.                  gastrointestinal                  system                           potential implications for gastrointestinal responses to exercise         0.7\n",
            "41261949 Caffeine exacerbates exercise-induced gut cell damage and is influenced by ADORA2A genotype but not CYP1A2 genotype: A preliminary study. intestinal epithelial cell damage toxicological mechanism                                                caffeine exacerbates exercise-induced damage         0.8\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.               adenosine receptors                 protein                                                                        non-specific blocker         0.9\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                 neuroinflammation        cellular pathway                                                                   can exacerbate or inhibit         0.7\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                             IL-1ÃŸ                 protein                                                                             reducing levels         0.8\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                         TNF-alpha                 protein                                                                             reducing levels         0.8\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                              IL-6                 protein                                                                             reducing levels         0.8\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                        glial cell                    cell                                                                       inhibiting activation         0.8\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                  oxidative damage               mechanism                                                                                    reversed         0.7\n",
            "41249138                                Effects of caffeine on neuroinflammation in anxiety and depression: a systematic review of rodent studies.                             brain                   organ                                affects areas involved in controlling anxiety and depression         0.7\n",
            "41246694                                                       Neurocognitive and Neurological Effects of Coffee and Caffeine: A Narrative Review.                         adenosine                 protein                                                                       inhibited by caffeine         0.8\n",
            "41246694                                                       Neurocognitive and Neurological Effects of Coffee and Caffeine: A Narrative Review.                             brain                   organ                                                    affects alertness, cognition, and memory         0.7\n",
            "41246694                                                       Neurocognitive and Neurological Effects of Coffee and Caffeine: A Narrative Review.                    nervous system                  system                                                       neuroprotective effects being studied         0.6\n",
            "41246694                                                       Neurocognitive and Neurological Effects of Coffee and Caffeine: A Narrative Review.                 anti-inflammatory               mechanism                                                       potential benefit conferred by coffee         0.5\n",
            "41246694                                                       Neurocognitive and Neurological Effects of Coffee and Caffeine: A Narrative Review.            drowsiness and fatigue               mechanism                                                               warded off by coffee drinking         0.7\n",
            "41242048          Decoding binary reaction model products (novel quercetin-glucose adducts): From identification to bitterness masking mechanisms.                        bitterness toxicological mechanism                                                                      masked by HF-3 (42.1%)         0.9\n",
            "41242048          Decoding binary reaction model products (novel quercetin-glucose adducts): From identification to bitterness masking mechanisms.               bitterness receptor        molecular target                       competition between HF-3 and caffeine for accessing the active pocket         0.9\n",
            "41236610                                                           The Effects of Energy Drinks on the Cardiovascular System: A Systematic Review.             cardiovascular system                   organ                                                        affected by energy drink consumption         0.7\n",
            "41236610                                                           The Effects of Energy Drinks on the Cardiovascular System: A Systematic Review.                       arrhythmias toxicological mechanism                                     potential risk associated with energy drink consumption         0.8\n",
            "41236610                                                           The Effects of Energy Drinks on the Cardiovascular System: A Systematic Review.                       tachycardia toxicological mechanism                                     potential risk associated with energy drink consumption         0.8\n",
            "\n",
            "âœ… Saved to caffeine_interactions.csv\n",
            "\n",
            "======================================================================\n",
            "  ANALYZING: nicotine\n",
            "======================================================================\n",
            "\n",
            "ðŸ” nicotine\n",
            "   Query: \"nicotine\" AND (toxicity OR toxicology OR \"molecular target\" OR protein OR gene ...\n",
            "  âœ“ Found 30 articles\n",
            "\n",
            "ðŸ“¥ Fetching...\n",
            "  âœ“ Fetched 30 articles\n",
            "\n",
            "ðŸ§  Extracting interactions...\n",
            "  [1/25]... âœ“ (4 found)\n",
            "  [2/25]... âœ—\n",
            "  [3/25]... âœ“ (2 found)\n",
            "  [4/25]... âœ—\n",
            "  [5/25]... âœ“ (7 found)\n",
            "  [6/25]... âœ“ (7 found)\n",
            "  [7/25]... âœ“ (3 found)\n",
            "  [8/25]... âœ—\n",
            "  [9/25]... âœ—\n",
            "  [10/25]... âœ—\n",
            "  [11/25]... âœ“ (7 found)\n",
            "  [12/25]... âœ—\n",
            "  [13/25]... âœ—\n",
            "  [14/25]... âœ“ (14 found)\n",
            "  [15/25]... âœ—\n",
            "  [16/25]... âœ“ (9 found)\n",
            "  [17/25]... âœ“ (8 found)\n",
            "  [18/25]... âœ“ (2 found)\n",
            "  [19/25]... âœ—\n",
            "  [20/25]... âœ—\n",
            "  [21/25]... âœ—\n",
            "  [22/25]... âœ“ (13 found)\n",
            "  [23/25]... âœ“ (2 found)\n",
            "  [24/25]... âœ“ (18 found)\n",
            "  [25/25]... âœ“ (7 found)\n",
            "\n",
            "======================================================================\n",
            "  RESULTS: 103 interactions extracted\n",
            "======================================================================\n",
            "\n",
            "    pmid                                                                                                                                   title                                          name                    type                                                                                                    interaction  confidence\n",
            "41260324                                                      Evaluating Cancer Risks: The Impact of Thirdhand Smoke Exposure on Carcinogenesis.                                      nicotine                chemical                                                                                     component of tobacco smoke         0.9\n",
            "41260324                                                      Evaluating Cancer Risks: The Impact of Thirdhand Smoke Exposure on Carcinogenesis.                             dermal absorption toxicological mechanism                                                                         route of exposure to nicotine from THS         0.8\n",
            "41260324                                                      Evaluating Cancer Risks: The Impact of Thirdhand Smoke Exposure on Carcinogenesis.                                    inhalation toxicological mechanism                                                                         route of exposure to nicotine from THS         0.8\n",
            "41260324                                                      Evaluating Cancer Risks: The Impact of Thirdhand Smoke Exposure on Carcinogenesis.                                     ingestion toxicological mechanism                                                                         route of exposure to nicotine from THS         0.8\n",
            "41256477                                                                    UGT35B1 is the principal enzyme mediating nicotine glycosylation in                                       nicotine                chemical                                                                                                     neurotoxic         0.9\n",
            "41256477                                                                    UGT35B1 is the principal enzyme mediating nicotine glycosylation in                                glucuronidation                 pathway                                                                                                 detoxification         0.9\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.       human bronchial epithelial cells (H292)                   organ                                                                             exposed to nicotine-rich e-liquids         0.7\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.                        mitochondrial function        cellular pathway                                                                                      potential for dysfunction         0.6\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.                              oxidative stress        cellular pathway                                                                                        potential for induction         0.6\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.                                  cytotoxicity toxicological mechanism                                                                                          induced in H292 cells         0.7\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.                                     apoptosis        cellular pathway                                                                                                       assessed         0.5\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.              mitochondrial membrane potential        cellular pathway                                                                                                       assessed         0.5\n",
            "41254430 Mechanistic toxicity profiling of nicotine-rich e-liquids: mitochondrial and oxidative stress responses in ALI-exposed bronchial cells.      reactive oxygen species (ROS) generation        cellular pathway                                                                                                       assessed         0.5\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.                         medial habenula (MHb)                   organ                                                                                affected by nicotine withdrawal         0.8\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.                 interpeduncular nucleus (IPN)                   organ                                                                                affected by nicotine withdrawal         0.8\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.               glutamatergic neurotransmission        cellular pathway                                                                   MHb axons release glutamate onto IPN neurons         0.7\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.                                     glutamate        neurotransmitter                                                                         released by MHb axons onto IPN neurons         0.9\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.        ionotropic glutamate receptors (iGluR)                 protein                                                                         expressed in rostral IPN (IPR) neurons         0.8\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.                           nicotine withdrawal toxicological mechanism                                                                                            aversive experience         0.9\n",
            "41253496                                    Ionotropic glutamate receptor function in interpeduncular nucleus is modulated by nicotine exposure.                                nervous system            organ system                                                                                   affects mood/affect, anxiety         0.7\n",
            "41253199                                                                                                Psychotropic effects of GLP-1R agonists.                                      nicotine               substance                                                                            involved in substance use disorders         0.8\n",
            "41253199                                                                                                Psychotropic effects of GLP-1R agonists.                               reward pathways        cellular pathway                                                                                                      modulated         0.7\n",
            "41253199                                                                                                Psychotropic effects of GLP-1R agonists.                                         neuro            organ system                                                                   neuropsychiatric and neuroprotective effects         0.6\n",
            "41249053                                            Nicotinic Modulation of Fast-spiking Neurons in Rat Somatosensory Cortex Across Development.    nicotinic acetylcholine receptors (nAChRs)                 protein                                                                                     nicotine signals at nAChRs         0.9\n",
            "41249053                                            Nicotinic Modulation of Fast-spiking Neurons in Rat Somatosensory Cortex Across Development. fast-spiking (FS) inhibitory cortical neurons                  neuron nicotine increases the frequency of spontaneous synaptic inputs to FS neurons during the second postnatal week         0.8\n",
            "\n",
            "âœ… Saved to nicotine_interactions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NON BATCH SERACH"
      ],
      "metadata": {
        "id": "zcTLcNiCotKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OLD CODE"
      ],
      "metadata": {
        "id": "6b5XG04GXjka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPROVED AGENT - Better search queries and extraction prompts\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 1: Install\n",
        "# ============================================================================\n",
        "import subprocess\n",
        "subprocess.check_call(['pip', 'install', '-q',\n",
        "    'langchain', 'langchain-google-genai', 'langgraph',\n",
        "    'pandas', 'google-generativeai', 'requests'])\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 2: Setup - CHANGE YOUR EMAIL HERE!!!\n",
        "# ============================================================================\n",
        "import os, json, re, time, requests, pandas as pd\n",
        "from typing import TypedDict, Annotated, Sequence, List, Dict, Any\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"NCBI_EMAIL\"] = \"Ukaegbudaniel33@gmail.com\"  # â† CHANGE THIS!\n",
        "\n",
        "print(f\"âœ… Email: {os.getenv('NCBI_EMAIL')}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 3: State\n",
        "# ============================================================================\n",
        "class CompoundState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    compound_name: str\n",
        "    search_query: str\n",
        "    pmids: List[str]\n",
        "    articles: List[Dict[str, Any]]\n",
        "    interactions: List[Dict[str, Any]]\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 4: Tools\n",
        "# ============================================================================\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "@tool\n",
        "def search_pubmed(compound: str, max_results: int = 50) -> str:\n",
        "    \"\"\"Search PubMed for articles on a chemical compound with toxicology focus.\n",
        "\n",
        "    Args:\n",
        "        compound: The search query for PubMed (can include boolean operators)\n",
        "        max_results: Maximum number of results to return (default: 30)\n",
        "\n",
        "    Returns:\n",
        "        JSON string with list of PubMed IDs (pmids)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        email = os.getenv(\"NCBI_EMAIL\")\n",
        "        if not email or \"example\" in email:\n",
        "            raise ValueError(\"âŒ REPLACE YOUR EMAIL IN THE CODE!\")\n",
        "        url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\"db\": \"pubmed\", \"term\": compound, \"retmax\": min(max_results, 100),\n",
        "                  \"rettype\": \"xml\", \"tool\": \"agent\", \"email\": email}\n",
        "        response = requests.get(url, params=params, timeout=20)\n",
        "\n",
        "        root = ET.fromstring(response.text)\n",
        "        pmids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
        "\n",
        "        print(f\"  âœ“ Found {len(pmids)} articles\")\n",
        "        return json.dumps({\"pmids\": pmids})\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ {e}\")\n",
        "        return json.dumps({\"pmids\": []})\n",
        "\n",
        "@tool\n",
        "def fetch_pubmed_articles(pmids_list: str) -> str:\n",
        "    \"\"\"Fetch full article metadata from PubMed using PMIDs.\n",
        "\n",
        "    Args:\n",
        "        pmids_list: JSON string containing list of PubMed IDs\n",
        "\n",
        "    Returns:\n",
        "        JSON string with article titles and abstracts\n",
        "    \"\"\"\n",
        "    try:\n",
        "        pmids = json.loads(pmids_list)\n",
        "        if not pmids:\n",
        "            return json.dumps({\"articles\": []})\n",
        "        email = os.getenv(\"NCBI_EMAIL\")\n",
        "        articles = []\n",
        "        for i in range(0, len(pmids), 50):\n",
        "            batch = pmids[i:i+50]\n",
        "            url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "            params = {\"db\": \"pubmed\", \"id\": \",\".join(batch), \"rettype\": \"xml\", \"email\": email}\n",
        "            response = requests.get(url, params=params, timeout=20)\n",
        "\n",
        "            root = ET.fromstring(response.text)\n",
        "            for article in root.findall(\".//PubmedArticle\"):\n",
        "                pmid_elem = article.find(\".//PMID\")\n",
        "                title_elem = article.find(\".//ArticleTitle\")\n",
        "                abstract_elem = article.find(\".//AbstractText\")\n",
        "\n",
        "                pmid = pmid_elem.text if pmid_elem is not None else \"\"\n",
        "                title = title_elem.text if title_elem is not None else \"\"\n",
        "                abstract = abstract_elem.text if abstract_elem is not None else \"\"\n",
        "\n",
        "                if pmid and abstract:\n",
        "                    articles.append({\"pmid\": pmid, \"title\": title, \"abstract\": abstract})\n",
        "\n",
        "            time.sleep(0.5)\n",
        "        print(f\"  âœ“ Fetched {len(articles)} articles\")\n",
        "        return json.dumps({\"articles\": articles})\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ {e}\")\n",
        "        return json.dumps({\"articles\": []})\n",
        "\n",
        "@tool\n",
        "def extract_with_llm(article_data: str) -> str:\n",
        "    \"\"\"Extract molecular interactions and toxicological mechanisms from an article abstract using LLM.\n",
        "\n",
        "    Args:\n",
        "        article_data: JSON string with compound, abstract, and pmid fields\n",
        "\n",
        "    Returns:\n",
        "        JSON string with extracted interactions and confidence scores\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(article_data)\n",
        "        compound = data.get(\"compound\", \"\")\n",
        "        abstract = data.get(\"abstract\", \"\")\n",
        "        pmid = data.get(\"pmid\", \"\")\n",
        "\n",
        "        if not abstract or len(abstract) < 50:\n",
        "            return json.dumps({\"pmid\": pmid, \"interactions\": []})\n",
        "\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.1)\n",
        "        prompt = f\"\"\"You are a toxicology and molecular biology expert. Extract biological and toxicological information about {compound} from the following abstract.\n",
        "\n",
        "ABSTRACT:\n",
        "{abstract}\n",
        "\n",
        "Extract the following information if present:\n",
        "1. Proteins/enzymes that interact with {compound}\n",
        "2. Genes that are affected or regulated\n",
        "3. Cellular pathways impacted\n",
        "4. Organs or systems affected\n",
        "5. Toxicological mechanisms or effects\n",
        "6. Molecular targets\n",
        "\n",
        "CRITICAL: You MUST respond with ONLY valid JSON. No explanations, no markdown, just raw JSON.\n",
        "\n",
        "If you find relevant information, use this format:\n",
        "{{\"interactions\": [{{\"type\": \"protein/gene/pathway/mechanism/organ\", \"name\": \"specific_name\", \"interaction\": \"how_it_interacts_or_is_affected\", \"confidence\": 0.9}}, ...]}}\n",
        "\n",
        "If NO relevant information found:\n",
        "{{\"interactions\": []}}\n",
        "\n",
        "Remember: Only respond with JSON, nothing else.\"\"\"\n",
        "\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "        # Clean up response - remove markdown code blocks if present\n",
        "        response_text = response.content.strip()\n",
        "        if response_text.startswith(\"```\"):\n",
        "            response_text = response_text.split(\"```\")[1]\n",
        "            if response_text.startswith(\"json\"):\n",
        "                response_text = response_text[4:]\n",
        "            response_text = response_text.strip()\n",
        "\n",
        "        try:\n",
        "            result = json.loads(response_text)\n",
        "        except:\n",
        "            result = {\"interactions\": []}\n",
        "\n",
        "        result[\"pmid\"] = pmid\n",
        "        return json.dumps(result)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"pmid\": pmid, \"interactions\": []})\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 5: Nodes\n",
        "# ============================================================================\n",
        "def search_node(state):\n",
        "    compound = state.get(\"compound_name\", \"\")\n",
        "\n",
        "    # Build a more targeted search query\n",
        "    # Prioritizes toxicology, molecular interaction, and mechanism studies\n",
        "    search_query = f'\"{compound}\" AND (toxicity OR toxicology OR \"molecular target\" OR protein OR gene OR pathway OR pharmacology OR mechanism OR hepatotoxicity OR nephrotoxicity OR neurotoxicity OR genotoxicity OR \"drug metabolism\" OR metabolism OR binding OR inhibitor OR receptor)'\n",
        "\n",
        "    print(f\"\\nðŸ” {compound}\")\n",
        "    print(f\"   Query: {search_query[:80]}...\")\n",
        "    result = json.loads(search_pubmed.invoke({\"compound\": search_query, \"max_results\": 30}))\n",
        "    return {**state, \"pmids\": result.get(\"pmids\", []), \"search_query\": search_query}\n",
        "\n",
        "def fetch_node(state):\n",
        "    pmids = state.get(\"pmids\", [])\n",
        "    if not pmids:\n",
        "        print(\"\\nðŸ“¥ No PMIDs to fetch\")\n",
        "        return state\n",
        "    print(f\"\\nðŸ“¥ Fetching...\")\n",
        "    result = json.loads(fetch_pubmed_articles.invoke(json.dumps(pmids)))\n",
        "    return {**state, \"articles\": result.get(\"articles\", [])}\n",
        "\n",
        "def extract_node(state):\n",
        "    articles, compound = state.get(\"articles\", []), state.get(\"compound_name\", \"\")\n",
        "    if not articles:\n",
        "        print(\"\\nðŸ§  No articles to extract\")\n",
        "        return state\n",
        "    print(f\"\\nðŸ§  Extracting interactions...\")\n",
        "    all_interactions = []\n",
        "\n",
        "    # Process all articles (or limit to 25 for speed)\n",
        "    max_articles = min(len(articles), 25)\n",
        "    for i, article in enumerate(articles[:max_articles]):\n",
        "        if not article.get(\"abstract\"):\n",
        "            continue\n",
        "        print(f\"  [{i+1}/{max_articles}]...\", end=\" \", flush=True)\n",
        "        result = json.loads(extract_with_llm.invoke(json.dumps({\n",
        "            \"compound\": compound,\n",
        "            \"abstract\": article[\"abstract\"],\n",
        "            \"pmid\": article[\"pmid\"]\n",
        "        })))\n",
        "        interactions = result.get(\"interactions\", [])\n",
        "        if interactions:\n",
        "            print(f\"âœ“ ({len(interactions)} found)\")\n",
        "            for inter in interactions:\n",
        "                all_interactions.append({\"pmid\": article[\"pmid\"], \"title\": article.get(\"title\", \"\"), **inter})\n",
        "        else:\n",
        "            print(\"âœ—\")\n",
        "        time.sleep(0.5)  # Reduced from 1s\n",
        "\n",
        "    return {**state, \"interactions\": all_interactions}\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 6: Create Agent\n",
        "# ============================================================================\n",
        "def create_agent():\n",
        "    graph = StateGraph(CompoundState)\n",
        "    graph.add_node(\"search\", search_node)\n",
        "    graph.add_node(\"fetch\", fetch_node)\n",
        "    graph.add_node(\"extract\", extract_node)\n",
        "    graph.add_edge(START, \"search\")\n",
        "    graph.add_edge(\"search\", \"fetch\")\n",
        "    graph.add_edge(\"fetch\", \"extract\")\n",
        "    graph.add_edge(\"extract\", END)\n",
        "    return graph.compile()\n",
        "\n",
        "agent = create_agent()\n",
        "print(\"âœ… Agent ready!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 7: Search function\n",
        "# ============================================================================\n",
        "def search_compound(compound_name: str):\n",
        "    print(f\"\\n{'='*70}\\n  ANALYZING: {compound_name}\\n{'='*70}\")\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=f\"Analyze {compound_name}\")],\n",
        "        \"compound_name\": compound_name,\n",
        "        \"search_query\": \"\",\n",
        "        \"pmids\": [],\n",
        "        \"articles\": [],\n",
        "        \"interactions\": []\n",
        "    }\n",
        "    result = agent.invoke(initial_state)\n",
        "    interactions = result.get(\"interactions\", [])\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  RESULTS: {len(interactions)} interactions extracted\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    if interactions:\n",
        "        df = pd.DataFrame(interactions)\n",
        "        # Display relevant columns\n",
        "        display_cols = [col for col in [\"compound_name\", \"pmid\", \"title\", \"name\", \"type\", \"interaction\", \"confidence\"] if col in df.columns]\n",
        "        print(df[display_cols].head(25).to_string(index=False))\n",
        "        print(f\"\\nâœ… Saved to {compound_name.lower().replace(' ', '_')}_interactions.csv\")\n",
        "        df.to_csv(f\"{compound_name.lower().replace(' ', '_')}_interactions.csv\", index=False)\n",
        "        return df\n",
        "    else:\n",
        "        print(\"âš ï¸ No interactions found. Try adjusting the compound name or search terms.\")\n",
        "    return pd.DataFrame()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "ce0aa6da-ab07-4e24-c6de-fd14c162a731",
        "id": "GsCBQaLFXmG2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core.pydantic_v1'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1996373515.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypedDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_genai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGoogleGenerativeAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_genai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGoogleGenerativeAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ChatGoogleGenerativeAI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_validator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_from_dict_or_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m from tenacity import (\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.pydantic_v1'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33bde3cc"
      },
      "source": [
        "# Task\n",
        "Update the installation cell `PQlKnTa9QsXU` to include `langchain-community` in both the `pip uninstall` and `pip install --upgrade` commands, and then execute this modified cell to resolve the `ModuleNotFoundError`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e222f4e"
      },
      "source": [
        "## Update Installation Cell\n",
        "\n",
        "### Subtask:\n",
        "Modify cell PQlKnTa9QsXU to include langchain-community in both the pip uninstall and pip install --upgrade commands to ensure all langchain ecosystem packages are updated to mutually compatible versions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58daee83"
      },
      "source": [
        "**Reasoning**:\n",
        "The user wants to modify the specified cell to include 'langchain-community' in both the uninstall and install commands. I will provide the updated code for cell PQlKnTa9QsXU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4f80957",
        "outputId": "8bb2a7ae-a692-44aa-981e-2548b53834bc"
      },
      "source": [
        "import subprocess\n",
        "# Uninstall problematic packages to ensure a clean slate before installing specific versions\n",
        "subprocess.check_call(['pip', 'uninstall', '-y', 'langchain', 'langchain-google-genai', 'langchain-core', 'langgraph', 'langchain-community'])\n",
        "# Install the latest compatible versions to avoid issues with old, pinned versions\n",
        "subprocess.check_call(['pip', 'install', '-q', '--upgrade',\n",
        "    'langchain', 'langchain-google-genai', 'langchain-core', 'langgraph', 'langchain-community',\n",
        "    'pandas', 'google-generativeai', 'requests'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccda5012"
      },
      "source": [
        "## Execute Installation Cell\n",
        "\n",
        "### Subtask:\n",
        "Execute the modified installation cell to apply the changes and attempt to resolve the ModuleNotFoundError.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2423416"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The installation cell `PQlKnTa9QsXU` was successfully updated to include `langchain-community` in both the `pip uninstall` and `pip install --upgrade` commands.\n",
        "*   The update operation completed without errors, as confirmed by the output `{\"stream\": {\"stdout\": \"0\"}}`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The modified installation cell, which now includes `langchain-community` in its `pip uninstall` and `pip install --upgrade` commands, should be executed to apply the package updates. This action is crucial for resolving the `ModuleNotFoundError` by ensuring all `langchain` ecosystem packages are updated to mutually compatible versions.\n"
      ]
    }
  ]
}